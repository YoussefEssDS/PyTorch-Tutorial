{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythorch Tutorial:\n",
    "\n",
    "Till now I didn't work with the MNSIT dataset on any of my ML problems, wierd enough, since this dataset is the big classic for machine learning tutorials, so I'll be using it for this tutorial.\n",
    "\n",
    "If you don't know about the MNIST dataset, well it's a dataset than contains images of hand written digits from 0 to 9. And the objectif is to predict hand written digits, clear enough. \n",
    "\n",
    "With PyTorch we won't be forced to download the dataset elsewhere, and we can do that through torchvision module.\n",
    "\n",
    "So without further ado let's get right into it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████▊| 9887744/9912422 [01:34<00:00, 73223.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                        | 0/28881 [00:00<?, ?it/s]\n",
      " 57%|████████████████████████████████████████▊                               | 16384/28881 [00:00<00:00, 106519.20it/s]\n",
      "32768it [00:00, 118959.19it/s]                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                      | 0/1648877 [00:00<?, ?it/s]\n",
      "  1%|▋                                                                     | 16384/1648877 [00:00<00:11, 141399.85it/s]\n",
      "  2%|█▍                                                                    | 32768/1648877 [00:00<00:11, 135898.01it/s]\n",
      "  3%|██                                                                    | 49152/1648877 [00:00<00:12, 128909.80it/s]\n",
      "  4%|██▊                                                                   | 65536/1648877 [00:00<00:12, 127578.40it/s]\n",
      "  5%|███▍                                                                  | 81920/1648877 [00:00<00:12, 126660.90it/s]\n",
      "  6%|████▏                                                                 | 98304/1648877 [00:01<00:12, 128739.89it/s]\n",
      "  7%|████▊                                                                | 114688/1648877 [00:01<00:12, 122981.06it/s]\n",
      "  8%|█████▍                                                               | 131072/1648877 [00:01<00:12, 121669.32it/s]\n",
      "  9%|██████▏                                                              | 147456/1648877 [00:01<00:12, 122528.49it/s]\n",
      " 10%|██████▊                                                              | 163840/1648877 [00:01<00:12, 121950.91it/s]\n",
      " 11%|███████▌                                                             | 180224/1648877 [00:01<00:12, 120966.11it/s]\n",
      " 12%|████████▏                                                            | 196608/1648877 [00:01<00:11, 122008.19it/s]\n",
      " 13%|████████▉                                                            | 212992/1648877 [00:01<00:12, 118610.67it/s]\n",
      " 14%|█████████▌                                                           | 229376/1648877 [00:02<00:11, 118641.15it/s]\n",
      " 15%|██████████▎                                                          | 245760/1648877 [00:02<00:11, 120339.29it/s]\n",
      " 16%|██████████▉                                                          | 262144/1648877 [00:02<00:11, 121586.57it/s]\n",
      " 17%|███████████▋                                                         | 278528/1648877 [00:02<00:11, 119569.95it/s]\n",
      " 18%|████████████▎                                                        | 294912/1648877 [00:02<00:11, 121032.71it/s]\n",
      " 19%|█████████████▏                                                        | 311296/1648877 [00:03<00:34, 38792.07it/s]\n",
      " 21%|██████████████▌                                                       | 344064/1648877 [00:03<00:25, 51990.64it/s]\n",
      " 22%|███████████████▋                                                      | 368640/1648877 [00:03<00:18, 68095.04it/s]\n",
      " 24%|████████████████▋                                                     | 393216/1648877 [00:04<00:14, 86020.52it/s]\n",
      " 25%|█████████████████▍                                                   | 417792/1648877 [00:04<00:11, 104146.05it/s]\n",
      " 27%|██████████████████▌                                                  | 442368/1648877 [00:04<00:11, 107046.74it/s]\n",
      " 28%|███████████████████▌                                                 | 466944/1648877 [00:04<00:10, 115285.08it/s]\n",
      " 29%|████████████████████▌                                                 | 483328/1648877 [00:08<01:35, 12183.21it/s]\n",
      " 38%|██████████████████████████▍                                           | 622592/1648877 [00:08<00:59, 17333.79it/s]\n",
      " 53%|█████████████████████████████████████▏                                | 876544/1648877 [00:08<00:31, 24675.82it/s]\n",
      " 59%|█████████████████████████████████████████▍                            | 974848/1648877 [00:10<00:22, 29520.89it/s]\n",
      " 64%|███████████████████████████████████████████▉                         | 1048576/1648877 [00:10<00:14, 40558.85it/s]\n",
      " 68%|██████████████████████████████████████████████▌                      | 1114112/1648877 [00:11<00:10, 49790.59it/s]\n",
      " 74%|██████████████████████████████████████████████████▋                  | 1212416/1648877 [00:11<00:06, 69224.58it/s]\n",
      " 77%|█████████████████████████████████████████████████████▏               | 1269760/1648877 [00:12<00:04, 79749.55it/s]\n",
      " 80%|███████████████████████████████████████████████████████▏             | 1318912/1648877 [00:12<00:03, 89090.33it/s]\n",
      " 82%|████████████████████████████████████████████████████████▌            | 1351680/1648877 [00:12<00:03, 96461.39it/s]\n",
      " 84%|█████████████████████████████████████████████████████████           | 1384448/1648877 [00:13<00:02, 102825.01it/s]\n",
      " 85%|██████████████████████████████████████████████████████████          | 1409024/1648877 [00:13<00:02, 105827.23it/s]\n",
      " 87%|███████████████████████████████████████████████████████████         | 1433600/1648877 [00:13<00:01, 108062.89it/s]\n",
      " 88%|████████████████████████████████████████████████████████████▏       | 1458176/1648877 [00:13<00:01, 111060.49it/s]\n",
      " 89%|████████████████████████████████████████████████████████████▊       | 1474560/1648877 [00:13<00:01, 111137.82it/s]\n",
      " 90%|█████████████████████████████████████████████████████████████▍      | 1490944/1648877 [00:14<00:01, 113266.70it/s]\n",
      " 91%|██████████████████████████████████████████████████████████████▏     | 1507328/1648877 [00:14<00:01, 112649.46it/s]\n",
      " 92%|██████████████████████████████████████████████████████████████▊     | 1523712/1648877 [00:14<00:01, 110732.41it/s]\n",
      " 93%|███████████████████████████████████████████████████████████████▌    | 1540096/1648877 [00:14<00:00, 114526.09it/s]\n",
      "9920512it [01:50, 73223.62it/s]                                                                                        \n",
      " 95%|████████████████████████████████████████████████████████████████▊   | 1572864/1648877 [00:14<00:00, 113946.18it/s]\n",
      " 96%|█████████████████████████████████████████████████████████████████▌  | 1589248/1648877 [00:14<00:00, 113139.36it/s]\n",
      " 97%|██████████████████████████████████████████████████████████████████▏ | 1605632/1648877 [00:15<00:00, 114841.82it/s]\n",
      " 98%|██████████████████████████████████████████████████████████████████▉ | 1622016/1648877 [00:15<00:00, 110183.64it/s]\n",
      " 99%|███████████████████████████████████████████████████████████████████▌| 1638400/1648877 [00:15<00:00, 109151.70it/s]\n",
      "1654784it [00:15, 81362.06it/s]                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "  0%|                                                                                         | 0/4542 [00:00<?, ?it/s]\n",
      "\n",
      "8192it [00:00, 20419.49it/s]                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1654784it [00:34, 81362.06it/s]"
     ]
    }
   ],
   "source": [
    "# Initializing train/test data:\n",
    "\n",
    "train=datasets.MNIST(\"\",train=True,download=True,transform=transforms.Compose([transforms.ToTensor()])) \n",
    "# 1st parameter stores the data locally,2nd,3rd self-explanatory and 4th transforms it into a Tensor. \n",
    "\n",
    "test=datasets.MNIST(\"\",train=False,download=True,transform=transforms.Compose([transforms.ToTensor()])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=torch.utils.data.DataLoader(train,batch_size=10,shuffle=True)\n",
    "testset=torch.utils.data.DataLoader(test,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of trainset is as follows: \n",
    "\n",
    "Each item from it is a list with 2 elements, first elemnet contains batch_size Tensors of values for the images. The second element is a tensor containing the output (correct answers) for those images.\n",
    "\n",
    "Note that each image is 28x28 with grayscale value between 0 & 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in trainset:\n",
    "    item\n",
    "    break\n",
    "    \n",
    "# Python remembers the last term of a loop which is the first one in this case since we breaked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So just so you won't be confused with this data structure, I'll give u hints:\n",
    "\n",
    "item is a 2 element list containing a batch of images and their resopective classes.\n",
    "batch size=len(item[0]).\n",
    "\n",
    "Since the images are 28x28 as I said before, you'd expect:\n",
    "\n",
    "item[0][0].shape to be a tensor of shape (1,28,28) Pytorch likes it this way (28,28,1) tensors are thus to be recshaped using the view method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c8b07f6240>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(item[0][0].view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important thing with classification problems is to make sure the data is balanced so to verify that let's see the percentage of each of the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "perDict={0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "total=0\n",
    "for batch in trainset:\n",
    "    y=batch[1]\n",
    "    for label in y:\n",
    "        perDict[int(label)]+=1\n",
    "        total+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 9.871666666666666,\n",
       " 1: 11.236666666666666,\n",
       " 2: 9.93,\n",
       " 3: 10.218333333333334,\n",
       " 4: 9.736666666666666,\n",
       " 5: 9.035,\n",
       " 6: 9.863333333333333,\n",
       " 7: 10.441666666666666,\n",
       " 8: 9.751666666666667,\n",
       " 9: 9.915}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l={key:100*value/total for key,value in perDict.items()}\n",
    "print(sum(l.values()))\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well it's quite balanced and we are not going to have troubles related to unbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after we got our data we will now implement our model. Let's start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cl1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (cl2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (cl3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (cl4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cl1=nn.Linear(784,64) #Takes input layer size (Number of neurones) and the following layer size(hyperparameter to tune)\n",
    "        self.cl2=nn.Linear(64,64)\n",
    "        self.cl3=nn.Linear(64,64)\n",
    "        self.cl4=nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.cl1(x))\n",
    "        x=F.relu(self.cl2(x))\n",
    "        x=F.relu(self.cl3(x))\n",
    "        x=self.cl4(x)\n",
    "        return(F.log_softmax(x,dim=1))\n",
    "net=Net()\n",
    "print(net) # Thanks to module we have a nice print of what our network looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4656, -2.3711, -2.2858, -2.3586, -2.1652, -2.2195, -2.3413, -2.3547,\n",
       "         -2.2126, -2.2877]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's pass some data through the forward prop model we built so far.\n",
    "\n",
    "X=torch.rand((28,28))\n",
    "X=X.view(1,28*28) # Torch wants this format for its outputs 1 here is the size of observations, if it was -1 instead that measn deal whith whatever size you get(-1 comes handy when we are doing batch learning)!\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see forward feed is working like a charm and notice that the calculations and weight initialization are all done internally, obviously we want that particular process to be random and we'll see further one how to do it. So yeah, we are on the right patha and one more step closer to the training phase. \n",
    "\n",
    "We'll start by specifying our learning method (optimizer) and our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0256, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0923, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.Adam(net.parameters(),lr=0.001)\n",
    "epochs=3 # relatively simple problem so no large number of epochs is needed.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in trainset:\n",
    "        X,y=batch\n",
    "        net.zero_grad()\n",
    "        output=net(X.view(-1,28*28))\n",
    "        loss= F.nll_loss(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  97.725 %\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "\n",
    "with torch.no_grad(): # this is used during eveluation we don't want to calculate gradients when testing right?\n",
    "    for batch in trainset:\n",
    "        X,y=batch\n",
    "        output=net(X.view(-1,28*28))\n",
    "        for idx,i in enumerate(output):\n",
    "            if torch.argmax(i)==y[idx]:\n",
    "                correct+=1\n",
    "            total+=1\n",
    "print('Accuracy is: ',100*correct/total,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind this is training set accuracy which always overestimates the test accuracy, so it does not reflect the quality of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
